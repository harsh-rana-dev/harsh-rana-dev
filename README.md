# Hi ğŸ‘‹, I'm Harsh

### Junior DataOps Engineer | Reliable Python Data Pipelines | Idempotency & Data Quality

---

ğŸ”­ Iâ€™m currently building **[Dataflow Sentinel](https://github.com/harsh-rana-dev/Dataflow-Sentinel)** â€” a production-style data pipeline that enforces schema validation, idempotent logic, and operational visibility.

ğŸ“« Reach me at **harshrana20025@gmail.com**

---

## Featured Projects

- **[Dataflow Sentinel](https://github.com/harsh-rana-dev/Dataflow-Sentinel)** â€” End-to-end Python DataOps pipeline with:
  - Data validation & schema enforcement
  - Idempotent ingestion and upsert logic
  - Operational logging & rerun safety
- **[90-Second Demo Video](https://www.loom.com/share/YOUR_LOOM_LINK)** â€” Quick walkthrough showing the pipeline in action

---

## Connect with me

[LinkedIn](https://linkedin.com/in/admin-harsh)

---

## Languages & Tools

**Core Data & Pipelines**

- Python ğŸ
- Pandas
- PostgreSQL
- SQLAlchemy
- Pydantic

**Deployment & Automation**

- Docker & Docker Compose
- Git & GitHub
- GitHub Actions (Cron Scheduling)
- pytest
- Bash / Shell Scripting
- YAML
- Linux

**Web / Data Acquisition**

- Scrapy
- Playwright
- Requests

---

## About This Profile

I focus on **building reliable, maintainable Python data pipelines** that prioritize **data correctness, operational safety, and rerun reliability**.  

My pipelines are designed to:

- Be **idempotent**, safe to rerun without creating duplicates
- **Validate incoming data** with schema enforcement
- Provide **operational visibility** through logs and monitoring
- Run consistently across environments using **Docker & Compose**
- Automate scheduling and execution using **GitHub Actions**

The current project, **Dataflow Sentinel**, demonstrates real-world DataOps concerns like safe retries, failure handling, and long-term maintainability.

---

## Goals & Philosophy

- Build **robust pipelines** that operate without manual intervention
- Demonstrate **DataOps best practices**: idempotency, validation, observability
- Focus on **reliability and repeatability** over flashy tech
- Share work transparently to signal **professional competence**
- Secure a **junior / contract DataOps role (EU/Remote)** to apply real-world pipelines in production
